{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec829924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import time\n",
    "\n",
    "from nltk.tokenize import sent_tokenize as _nltk_sent_tokenize\n",
    "def safe_sent_tokenize(text: str):\n",
    "    try:\n",
    "        return _nltk_sent_tokenize(text)\n",
    "    except LookupError:\n",
    "        for pkg in (\"punkt_tab\", \"punkt\"):\n",
    "            try:\n",
    "                nltk.download(pkg, quiet=True)\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "            return _nltk_sent_tokenize(text)\n",
    "        except Exception:\n",
    "            return re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('punkt_tab', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "    nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "    nltk.download('omw-1.4', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Advanced Multi-Model Employee Review Analysis Pipeline Initialized\")\n",
    "\n",
    "print(\"Phase 1: Loading and Exploring New Data Structure\")\n",
    "\n",
    "def load_and_explore_data(file_path):\n",
    "    \"\"\"Load and explore the new data structure\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded successfully: {len(df)} reviews\")\n",
    "        print(f\"Companies: {df['Company'].nunique()}\")\n",
    "        print(f\"Date range: {df['As Of Date'].min()} to {df['As Of Date'].max()}\")\n",
    "        print(f\"Countries: {df['Author Country'].nunique()}\")\n",
    "        \n",
    "        print(f\"\\nColumns ({len(df.columns)}):\")\n",
    "        for i, col in enumerate(df.columns):\n",
    "            print(f\"  {i+1:2d}. {col}\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da649163",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPhase 2: Enhanced HCF Framework & Dimension-Specific Analysis\")\n",
    "\n",
    "class EnhancedHCFAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.hcf_dimensions = {\n",
    "            \"Direct_Management\": {\n",
    "                \"description\": \"\"\"A supervisor-subordinate relationship is inherently hierarchal, which also\n",
    "                means that it is inherently complex with multiple potential points of failure. Getting instructions\n",
    "                about what to do and how to do it are never easy as it decreases the sense of autonomy in\n",
    "                multiple ways. In this dimension we assess the positive qualities of these relationships with an\n",
    "                emphasis on the working relationship, the support of employee development and on general\n",
    "                caring for the employee. In general, positive manager-employee relationships encourages\n",
    "                productivity and collaboration among teams. When there's mutual respect, care, and\n",
    "                communications between a manager and an employee, there's more willingness on both ends to\n",
    "                offer support and perform well.\"\"\",\n",
    "                \"rating_columns\": [\"Rating: Senior Management\"],\n",
    "                \"text_columns\": [\"PROs\", \"CONs\", \"Advice to Management\"],\n",
    "                \"keywords\": [\"management\", \"supervisor\", \"leadership\", \"boss\", \"manager\", \"director\", \"team lead\", \n",
    "                           \"executive\", \"1:1\", \"performance review\", \"feedback\", \"guidance\", \"support\", \"mentoring\"],\n",
    "                \"sentiment_threshold\": 0.1,\n",
    "                \"focus_areas\": [\"supervision quality\", \"employee development support\", \"manager-employee relationships\", \n",
    "                              \"communication effectiveness\", \"decision-making processes\", \"career guidance\"]\n",
    "            },\n",
    "            \"Organizational_Alignment\": {\n",
    "                \"description\": \"\"\"Organizational alignment is a shared understanding of the positive\n",
    "                mission, philosophy and approaches that underlie the path and methods of any company. It\n",
    "                allows all members of an organization, from entry-level positions to executive managers, to\n",
    "                share common goals and vision for the organization and to be proud of their joint mission. In\n",
    "                this dimension we assess the connection employees have with the values of the company, the\n",
    "                sense of mission, and the meaning that they get from their workplace. In general, good\n",
    "                organizational alignment helps with both motivation toward common organizational goals, a\n",
    "                shared understanding of how to treat each other to accomplish goals, and the coordination of all\n",
    "                actions and actors toward that goal.\"\"\",\n",
    "                \"rating_columns\": [\"Rating: Culture & Values\"],\n",
    "                \"text_columns\": [\"PROs\", \"CONs\", \"Summary\"],\n",
    "                \"keywords\": [\"mission\", \"vision\", \"goals\", \"strategy\", \"alignment\", \"purpose\", \"direction\", \n",
    "                           \"objectives\", \"values\", \"philosophy\", \"approach\", \"company culture\", \"shared vision\"],\n",
    "                \"sentiment_threshold\": 0.1,\n",
    "                \"focus_areas\": [\"company mission clarity\", \"strategic alignment\", \"shared values understanding\", \n",
    "                              \"organizational goals\", \"company direction\", \"cultural philosophy\"]\n",
    "            },\n",
    "            \"Engagement\": {\n",
    "                \"description\": \"\"\"Engagement is the level of commitment and emotional investment that employees\n",
    "                have toward their job and their organization. Engagement is not just about job satisfaction or\n",
    "                happiness, it is also about the level of involvement with their job, colleagues, and organization.\n",
    "                Engaged employees are enthusiastic about their work, are willing to go above and beyond what\n",
    "                is expected of them and are more likely to be loyal to their employer. In this dimension we\n",
    "                assess motivation, connection with the company, and the ability of the employee to reach their\n",
    "                potential to address the difficulties present in any job. In general, high employee engagement is\n",
    "                crucial for creating a positive and productive workplace culture that fosters growth and success\n",
    "                for both employees and the company.\"\"\",\n",
    "                \"rating_columns\": [\"Rating: Overall\"],\n",
    "                \"text_columns\": [\"PROs\", \"CONs\", \"Summary\"],\n",
    "                \"keywords\": [\"engagement\", \"motivation\", \"commitment\", \"involvement\", \"passion\", \"enthusiasm\", \n",
    "                           \"dedication\", \"satisfaction\", \"fulfillment\", \"excitement\", \"job satisfaction\"],\n",
    "                \"sentiment_threshold\": 0.1,\n",
    "                \"focus_areas\": [\"work motivation\", \"job satisfaction\", \"employee involvement\", \"career commitment\", \n",
    "                              \"daily excitement\", \"emotional investment\"]\n",
    "            },\n",
    "            \"Innovation\": {\n",
    "                \"description\": \"\"\"Innovation is the process of creating something new or improved. It involves\n",
    "                finding, testing, and improving novel and creative solutions to problems or challenges. It also\n",
    "                involves developing new ideas, products, or services. Innovation is an important driver of\n",
    "                progress and growth for all companies. In this dimension we assess the company's approach to\n",
    "                innovation and the degree to which it implicitly and explicitly encourages or discourages it, from\n",
    "                a company's treatment of mistakes to the outright acceptance of new ideas. In general, the more\n",
    "                innovative a company is, the more likely it is to be successful over time.\"\"\",\n",
    "                \"rating_columns\": [\"Rating: Overall\"],\n",
    "                \"text_columns\": [\"PROs\", \"CONs\", \"Summary\"],\n",
    "                \"keywords\": [\"innovation\", \"creative\", \"experimental\", \"new ideas\", \"cutting-edge\", \"technology\", \n",
    "                           \"research\", \"experimentation\", \"breakthrough\", \"inventive\", \"novel solutions\"],\n",
    "                \"sentiment_threshold\": 0.1,\n",
    "                \"focus_areas\": [\"creativity encouragement\", \"new technology development\", \"experimentation support\", \n",
    "                              \"forward-thinking culture\", \"research projects\", \"mistake tolerance\"]\n",
    "            },\n",
    "            \"Organizational_Effectiveness\": {\n",
    "                \"description\": \"\"\"Organizational effectiveness is the ability of a group to achieve\n",
    "                its goals and objectives efficiently and with little waste (inputs, effort, time, energy, attention).\n",
    "                Organizational effectiveness is a reflection of how well an organization uses its human and non-human\n",
    "                resources to achieve its mission and objectives. In this dimension we assess whether\n",
    "                people are given the tools they need for their jobs, the degree of collaboration, and the level of\n",
    "                bureaucratic burden. In general, organizations with a high degree of organizational\n",
    "                effectiveness are like well-oiled machines, providing a high level of output with inputs available.\"\"\",\n",
    "                \"rating_columns\": [\"Rating: Work/Life Balance\"],\n",
    "                \"text_columns\": [\"PROs\", \"CONs\", \"Summary\"],\n",
    "                \"keywords\": [\"efficiency\", \"productivity\", \"process\", \"workflow\", \"tools\", \"systems\", \"organization\", \n",
    "                           \"work-life balance\", \"flexibility\", \"resources\", \"collaboration\", \"bureaucracy\"],\n",
    "                \"sentiment_threshold\": 0.1,\n",
    "                \"focus_areas\": [\"operational efficiency\", \"work processes\", \"resource management\", \"productivity tools\", \n",
    "                              \"work-life balance\", \"bureaucratic burden\"]\n",
    "            },\n",
    "            \"Emotional_Connection\": {\n",
    "                \"description\": \"\"\"Emotional connection is the feeling of being emotionally attached,\n",
    "                invested, and engaged with the workplace and co-workers. When employees feel emotionally\n",
    "                connected, they are more likely to invest time, energy, and resources. Emotional connection can\n",
    "                also foster trust, loyalty, and commitment. In this dimension we assess the desire to stay at the\n",
    "                workplace, see their futures as intertwined, and the desire to recommend the workplace to others.\n",
    "                In general, high emotional connection brings a sense of connection, satisfaction, productivity,\n",
    "                purpose, and fulfillment.\"\"\",\n",
    "                \"rating_columns\": [\"Rating: Culture & Values\"],\n",
    "                \"text_columns\": [\"PROs\", \"CONs\", \"Summary\"],\n",
    "                \"keywords\": [\"culture\", \"values\", \"pride\", \"loyalty\", \"belonging\", \"family\", \"community\", \n",
    "                           \"atmosphere\", \"amazing\", \"love\", \"passion\", \"excitement\", \"emotional attachment\"],\n",
    "                \"sentiment_threshold\": 0.1,\n",
    "                \"focus_areas\": [\"company pride\", \"emotional attachment\", \"workplace satisfaction\", \"team bonding\", \n",
    "                              \"company culture\", \"future commitment\"]\n",
    "            },\n",
    "            \"Extrinsic_Rewards\": {\n",
    "                \"description\": \"\"\"Extrinsic rewards refer to rewards that are external to an individual such as\n",
    "                money, prizes, or recognition. These rewards are intended to motivate the individual to perform\n",
    "                better or continue engaging in a certain behavior, but do they?\n",
    "                Extrinsic rewards have been shown to be effective in motivating individuals in the short term.\n",
    "                However, extrinsic rewards have some limitations and are often ineffective in motivating\n",
    "                individuals in the long term, as they do not address intrinsic motivation or interest in the work\n",
    "                itself. In some cases, extrinsic rewards can have a negative effect on intrinsic motivation as\n",
    "                individuals become over-focused on the reward itself. In this dimension we assess\n",
    "                compensation, opportunities for advancement, and benefits. In general, when we think about\n",
    "                rewards, we usually think about a set of extrinsic rewards.\"\"\",\n",
    "                \"rating_columns\": [\"Rating: Comp & Benefits\", \"Rating: Career Opportunities\"],\n",
    "                \"text_columns\": [\"PROs\", \"CONs\", \"Summary\"],\n",
    "                \"keywords\": [\"salary\", \"benefits\", \"compensation\", \"bonus\", \"promotion\", \"career\", \"pay\", \n",
    "                           \"rewards\", \"perks\", \"stock\", \"advancement\", \"growth\", \"recognition\"],\n",
    "                \"sentiment_threshold\": 0.1,\n",
    "                \"focus_areas\": [\"compensation structure\", \"benefits package\", \"career growth opportunities\", \n",
    "                              \"financial rewards\", \"promotion pathways\", \"recognition systems\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.models = self._initialize_models()\n",
    "        \n",
    "    def _initialize_models(self):\n",
    "        \"\"\"Initialize different summarization and analysis models\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        try:\n",
    "            models['bart'] = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "            print(\"BART model loaded\")\n",
    "        except:\n",
    "            print(\"BART model not available\")\n",
    "            \n",
    "        try:\n",
    "            models['distilbart'] = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "            print(\"DistilBART model loaded\")\n",
    "        except:\n",
    "            print(\"DistilBART model not available\")\n",
    "            \n",
    "        try:\n",
    "            models['t5'] = pipeline(\"summarization\", model=\"t5-base\")\n",
    "            print(\"T5 model loaded\")\n",
    "        except:\n",
    "            print(\"T5 model not available\")\n",
    "            \n",
    "        try:\n",
    "            models['sentence_bert'] = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "            print(\"✅ Sentence-BERT model loaded\")\n",
    "        except:\n",
    "            print(\"⚠️ Sentence-BERT model not available\")\n",
    "            \n",
    "        return models\n",
    "    \n",
    "    def analyze_company_dimensions(self, company_data):\n",
    "        \"\"\"Analyze a company across all HCF dimensions\"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        for dimension, config in self.hcf_dimensions.items():\n",
    "            dimension_analysis = self._analyze_single_dimension(company_data, dimension, config)\n",
    "            analysis[dimension] = dimension_analysis\n",
    "            \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_single_dimension(self, company_data, dimension, config):\n",
    "        \"\"\"Analyze a single HCF dimension for a company\"\"\"\n",
    "        analysis = {\n",
    "            'dimension': dimension,\n",
    "            'description': config['description'],\n",
    "            'rating_scores': [],\n",
    "            'text_analysis': {},\n",
    "            'summary': '',\n",
    "            'sentiment': 'neutral',\n",
    "            'strength_score': 0.0,\n",
    "            'dimension_specific_insights': [],\n",
    "            'model_comparison': {} \n",
    "        }\n",
    "        \n",
    "        for rating_col in config['rating_columns']:\n",
    "            if rating_col in company_data.columns:\n",
    "                ratings = company_data[rating_col].dropna()\n",
    "                if len(ratings) > 0:\n",
    "                    analysis['rating_scores'].extend(ratings.tolist())\n",
    "        \n",
    "        for text_col in config['text_columns']:\n",
    "            if text_col in company_data.columns:\n",
    "                text_data = company_data[text_col].dropna()\n",
    "                if len(text_data) > 0:\n",
    "                    text_analysis = self._analyze_text_content_dimension_specific(text_data, config)\n",
    "                    analysis['text_analysis'][text_col] = text_analysis\n",
    "        \n",
    "        analysis['summary'], analysis['model_comparison'] = self._generate_dimension_specific_summary_with_comparison(company_data, dimension, config)\n",
    "        \n",
    "        analysis['strength_score'] = self._calculate_strength_score(analysis)\n",
    "        analysis['sentiment'] = self._classify_sentiment(analysis['strength_score'])\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_text_content_dimension_specific(self, text_data, config):\n",
    "        \"\"\"Analyze text content with dimension-specific focus\"\"\"\n",
    "        analysis = {\n",
    "            'keyword_matches': [],\n",
    "            'sentiment_scores': [],\n",
    "            'text_length': 0,\n",
    "            'key_themes': [],\n",
    "            'dimension_relevant_sentences': [],\n",
    "            'focus_area_coverage': {}\n",
    "        }\n",
    "        \n",
    "        for text in text_data:\n",
    "            if pd.notna(text) and isinstance(text, str):\n",
    "                text_lower = text.lower()\n",
    "                for keyword in config['keywords']:\n",
    "                    if keyword.lower() in text_lower:\n",
    "                        analysis['keyword_matches'].append(keyword)\n",
    "                \n",
    "                for focus_area in config['focus_areas']:\n",
    "                    if focus_area.lower() in text_lower:\n",
    "                        if focus_area not in analysis['focus_area_coverage']:\n",
    "                            analysis['focus_area_coverage'][focus_area] = []\n",
    "                        analysis['focus_area_coverage'][focus_area].append(text)\n",
    "                \n",
    "                blob = TextBlob(text)\n",
    "                analysis['sentiment_scores'].append(blob.sentiment.polarity)\n",
    "                \n",
    "                analysis['text_length'] += len(text)\n",
    "                \n",
    "                relevance_score = self._calculate_text_relevance(text, config)\n",
    "                if relevance_score > 0.2:\n",
    "                    analysis['dimension_relevant_sentences'].append((text, relevance_score))\n",
    "        \n",
    "        if analysis['sentiment_scores']:\n",
    "            analysis['key_themes'] = self._extract_dimension_specific_themes(text_data, config)\n",
    "            \n",
    "        return analysis\n",
    "    \n",
    "    def _calculate_text_relevance(self, text, config):\n",
    "        \"\"\"Calculate how relevant a text is to a specific dimension\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        relevance_score = 0.0\n",
    "        \n",
    "        keyword_matches = sum(1 for keyword in config['keywords'] if keyword.lower() in text_lower)\n",
    "        relevance_score += (keyword_matches / len(config['keywords'])) * 0.5\n",
    "        \n",
    "        focus_matches = sum(1 for focus in config['focus_areas'] if focus.lower() in text_lower)\n",
    "        relevance_score += (focus_matches / len(config['focus_areas'])) * 0.3\n",
    "        \n",
    "        length_score = min(len(text) / 200.0, 1.0)\n",
    "        relevance_score += length_score * 0.2\n",
    "        \n",
    "        return relevance_score\n",
    "    \n",
    "    def _extract_dimension_specific_themes(self, text_data, config):\n",
    "        \"\"\"Extract themes specific to a particular dimension\"\"\"\n",
    "        all_text = \" \".join([str(t) for t in text_data if pd.notna(t)])\n",
    "        words = word_tokenize(all_text.lower())\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word.isalnum() and len(word) > 3 and word not in stop_words]\n",
    "        \n",
    "        dimension_related_words = []\n",
    "        for word in words:\n",
    "            is_related = any(keyword.lower() in word.lower() or word.lower() in keyword.lower() \n",
    "                           for keyword in config['keywords'] + config['focus_areas'])\n",
    "            if is_related:\n",
    "                dimension_related_words.extend([word] * 3)\n",
    "            else:\n",
    "                dimension_related_words.append(word)\n",
    "        \n",
    "        word_freq = {}\n",
    "        for word in dimension_related_words:\n",
    "            word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        \n",
    "        sorted_themes = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [theme[0] for theme in sorted_themes[:10]]\n",
    "    \n",
    "    def _generate_dimension_specific_summary_with_comparison(self, company_data, dimension, config):\n",
    "        \"\"\"Generate dimension-specific summary using multiple approaches with model comparison\"\"\"\n",
    "        summaries = []\n",
    "        model_comparison = {}\n",
    "        \n",
    "        dimension_text = self._extract_dimension_specific_text(company_data, dimension, config)\n",
    "        \n",
    "        if not dimension_text.strip():\n",
    "            return f\"No dimension-specific data available for {dimension}\", {}\n",
    "        \n",
    "        focused_summary = self._create_focused_extractive_summary(dimension_text, dimension, config)\n",
    "        summaries.append(f\"Focused: {focused_summary}\")\n",
    "        \n",
    "        if len(dimension_text) > 100:\n",
    "            model_comparison = self._compare_summarization_models(dimension_text, dimension, config)\n",
    "            if model_comparison:\n",
    "                for model_name, result in model_comparison.items():\n",
    "                    if result.get('summary'):\n",
    "                        summaries.append(f\"{model_name}: {result['summary']}\")\n",
    "        \n",
    "        keyword_summary = self._create_keyword_based_summary(dimension_text, dimension, config)\n",
    "        summaries.append(f\"Keyword-based: {keyword_summary}\")\n",
    "        \n",
    "        return \" | \".join(summaries), model_comparison\n",
    "    \n",
    "    def _compare_summarization_models(self, text, dimension, config):\n",
    "        \"\"\"Compare different summarization models\"\"\"\n",
    "        comparison = {}\n",
    "        \n",
    "        prompt = f\"Summarize employee feedback about {dimension.replace('_',' ').lower()} focusing on: {config['description'][:200]}... \"\n",
    "        input_text = prompt + text[:1024]\n",
    "        \n",
    "        max_len = min(80, len(input_text.split()) // 2)\n",
    "        max_len = max(max_len, 20)\n",
    "        \n",
    "        if 'bart' in self.models:\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                bart_summary = self.models['bart'](\n",
    "                    input_text,\n",
    "                    max_length=max_len,\n",
    "                    min_length=20\n",
    "                )[0]['summary_text']\n",
    "                bart_time = time.time() - start_time\n",
    "                \n",
    "                comparison['BART'] = {\n",
    "                    'summary': bart_summary,\n",
    "                    'time': bart_time,\n",
    "                    'input_length': len(input_text.split()),\n",
    "                    'output_length': len(bart_summary.split()),\n",
    "                    'compression_ratio': len(bart_summary.split()) / max(1, len(input_text.split()))\n",
    "                }\n",
    "            except Exception as e:\n",
    "                comparison['BART'] = {'error': str(e)}\n",
    "        \n",
    "        if 'distilbart' in self.models:\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                distilbart_summary = self.models['distilbart'](\n",
    "                    input_text,\n",
    "                    max_length=max_len,\n",
    "                    min_length=20\n",
    "                )[0]['summary_text']\n",
    "                distilbart_time = time.time() - start_time\n",
    "                \n",
    "                comparison['DistilBART'] = {\n",
    "                    'summary': distilbart_summary,\n",
    "                    'time': distilbart_time,\n",
    "                    'input_length': len(input_text.split()),\n",
    "                    'output_length': len(distilbart_summary.split()),\n",
    "                    'compression_ratio': len(distilbart_summary.split()) / max(1, len(input_text.split()))\n",
    "                }\n",
    "            except Exception as e:\n",
    "                comparison['DistilBART'] = {'error': str(e)}\n",
    "        \n",
    "        if 't5' in self.models:\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                t5_summary = self.models['t5'](\n",
    "                    input_text,\n",
    "                    max_length=max_len,\n",
    "                    min_length=20\n",
    "                )[0]['summary_text']\n",
    "                t5_time = time.time() - start_time\n",
    "                \n",
    "                comparison['T5'] = {\n",
    "                    'summary': t5_summary,\n",
    "                    'time': t5_time,\n",
    "                    'input_length': len(input_text.split()),\n",
    "                    'output_length': len(t5_summary.split()),\n",
    "                    'compression_ratio': len(t5_summary.split()) / max(1, len(input_text.split()))\n",
    "                }\n",
    "            except Exception as e:\n",
    "                comparison['T5'] = {'error': str(e)}\n",
    "        \n",
    "        return comparison\n",
    "    \n",
    "    def _extract_dimension_specific_text(self, company_data, dimension, config):\n",
    "        \"\"\"Extract text that is most relevant to a specific dimension\"\"\"\n",
    "        relevant_texts = []\n",
    "        \n",
    "        for text_col in config['text_columns']:\n",
    "            if text_col in company_data.columns:\n",
    "                text_data = company_data[text_col].dropna()\n",
    "                for text in text_data:\n",
    "                    if pd.notna(text) and isinstance(text, str):\n",
    "                        relevance = self._calculate_text_relevance(text, config)\n",
    "                        if relevance > 0.1:\n",
    "                            relevant_texts.append((text, relevance))\n",
    "        \n",
    "        relevant_texts.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_texts = relevant_texts[:8]\n",
    "        \n",
    "        return \" \".join([text[0] for text in top_texts])\n",
    "    \n",
    "    def _create_focused_extractive_summary(self, text, dimension, config):\n",
    "        \"\"\"Create extractive summary focused on dimension-specific content\"\"\"\n",
    "        sentences = safe_sent_tokenize(text)\n",
    "        dimension_sentences = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            s_low = sentence.lower()\n",
    "            keyword_count = sum(1 for keyword in config['keywords'] if keyword.lower() in s_low)\n",
    "            focus_count   = sum(1 for focus in config['focus_areas'] if focus.lower() in s_low)\n",
    "            relevance_score = keyword_count + focus_count\n",
    "            \n",
    "            if relevance_score > 0:\n",
    "                dimension_sentences.append((sentence.strip(), relevance_score))\n",
    "        \n",
    "        dimension_sentences.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_sentences = [s for s, _ in dimension_sentences[:4]]\n",
    "        \n",
    "        if not top_sentences:\n",
    "            return f\"Limited {dimension.replace('_',' ').lower()} specific feedback available\"\n",
    "        \n",
    "        return \". \".join(top_sentences)\n",
    "    \n",
    "    def _create_keyword_based_summary(self, text, dimension, config):\n",
    "        \"\"\"Create summary based on dimension keywords and focus areas\"\"\"\n",
    "        sentences = safe_sent_tokenize(text)\n",
    "        keyword_sentences = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            s_low = sentence.lower()\n",
    "            keywords_found = [keyword for keyword in config['keywords'] if keyword.lower() in s_low]\n",
    "            focus_found    = [focus for focus in config['focus_areas'] if focus.lower() in s_low]\n",
    "            \n",
    "            if keywords_found or focus_found:\n",
    "                keyword_sentences.append((sentence.strip(), len(keywords_found) + len(focus_found)))\n",
    "        \n",
    "        if not keyword_sentences:\n",
    "            return f\"No {dimension.replace('_',' ').lower()} specific content identified\"\n",
    "        \n",
    "        keyword_sentences.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_sentences = [s for s, _ in keyword_sentences[:3]]\n",
    "        \n",
    "        return \". \".join(top_sentences)\n",
    "    \n",
    "    def _calculate_strength_score(self, analysis):\n",
    "        \"\"\"Calculate overall strength score for a dimension\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        if analysis['rating_scores']:\n",
    "            avg_rating = np.mean(analysis['rating_scores'])\n",
    "            score += (avg_rating / 5.0) * 0.4\n",
    "        \n",
    "        if analysis['text_analysis']:\n",
    "            all_sentiments = []\n",
    "            for text_analysis in analysis['text_analysis'].values():\n",
    "                if text_analysis['sentiment_scores']:\n",
    "                    all_sentiments.extend(text_analysis['sentiment_scores'])\n",
    "            \n",
    "            if all_sentiments:\n",
    "                avg_sentiment = np.mean(all_sentiments)\n",
    "                score += (avg_sentiment + 1) * 0.15\n",
    "        \n",
    "        total_relevant_content = sum(len(ta['dimension_relevant_sentences']) for ta in analysis['text_analysis'].values())\n",
    "        content_score = min(total_relevant_content / 5.0, 1.0)\n",
    "        score += content_score * 0.3\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _classify_sentiment(self, score):\n",
    "        \"\"\"Classify sentiment based on strength score\"\"\"\n",
    "        if score >= 0.7:\n",
    "            return 'positive'\n",
    "        elif score <= 0.3:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe3b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPhase 3: Company Analysis and Reporting\")\n",
    "\n",
    "class CompanyAnalyzer:\n",
    "    def __init__(self, hcf_analyzer):\n",
    "        self.hcf_analyzer = hcf_analyzer\n",
    "    \n",
    "    def analyze_all_companies(self, df):\n",
    "        \"\"\"Analyze all companies in the dataset\"\"\"\n",
    "        companies = df['Company'].unique()\n",
    "        company_analyses = {}\n",
    "        \n",
    "        print(f\"Analyzing {len(companies)} companies...\")\n",
    "        \n",
    "        for i, company in enumerate(companies, 1):\n",
    "            print(f\"  {i}/{len(companies)}: Analyzing {company}\")\n",
    "            company_data = df[df['Company'] == company]\n",
    "            company_analysis = self.hcf_analyzer.analyze_company_dimensions(company_data)\n",
    "            company_analyses[company] = company_analysis\n",
    "        \n",
    "        return company_analyses\n",
    "    \n",
    "    def generate_company_report(self, company_name, company_analysis):\n",
    "        \"\"\"Generate comprehensive report for a single company\"\"\"\n",
    "        report = f\"\\nCOMPANY ANALYSIS REPORT: {company_name}\\n\"\n",
    "        report += \"=\" * 80 + \"\\n\"\n",
    "        \n",
    "        overall_scores = [analysis['strength_score'] for analysis in company_analysis.values()]\n",
    "        overall_score = np.mean(overall_scores)\n",
    "        overall_sentiment = self.hcf_analyzer._classify_sentiment(overall_score)\n",
    "        \n",
    "        report += f\" Overall COMPANY SCORE: {overall_score:.3f} ({overall_sentiment.upper()})\\n\\n\"\n",
    "        \n",
    "        for dimension, analysis in company_analysis.items():\n",
    "            report += f\"   Score: {analysis['strength_score']:.3f} ({analysis['sentiment']})\\n\"\n",
    "            report += f\"   Description: {analysis['description'][:100]}...\\n\"\n",
    "            \n",
    "            if analysis['rating_scores']:\n",
    "                report += f\"   Rating Average: {np.mean(analysis['rating_scores']):.2f}/5.0\\n\"\n",
    "            \n",
    "            if analysis['summary']:\n",
    "                report += f\"   Summary: {analysis['summary']}\\n\"\n",
    "            \n",
    "            if analysis['model_comparison']:\n",
    "                report += f\"   Model Comparison:\\n\"\n",
    "                for model_name, result in analysis['model_comparison'].items():\n",
    "                    if 'error' not in result:\n",
    "                        report += f\"     {model_name}: {result['time']:.3f}s, {result['compression_ratio']:.2f} ratio\\n\"\n",
    "                    else:\n",
    "                        report += f\"     {model_name}: Error - {result['error']}\\n\"\n",
    "            \n",
    "            if analysis['text_analysis']:\n",
    "                total_relevant = sum(len(ta['dimension_relevant_sentences']) for ta in analysis['text_analysis'].values())\n",
    "                report += f\"   Relevant Content: {total_relevant} sentences\\n\"\n",
    "            \n",
    "            report += \"\\n\"\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def generate_model_comparison_summary(self, company_analyses):\n",
    "        \"\"\"Generate summary of model performance across all companies\"\"\"\n",
    "        print(\"\\nMODEL COMPARISON SUMMARY:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        model_stats = {}\n",
    "        \n",
    "        for company_name, company_analysis in company_analyses.items():\n",
    "            for dimension, analysis in company_analysis.items():\n",
    "                if 'model_comparison' in analysis and analysis['model_comparison']:\n",
    "                    for model_name, result in analysis['model_comparison'].items():\n",
    "                        if 'error' not in result:\n",
    "                            if model_name not in model_stats:\n",
    "                                model_stats[model_name] = {\n",
    "                                    'total_time': 0,\n",
    "                                    'total_compression': 0,\n",
    "                                    'count': 0,\n",
    "                                    'errors': 0\n",
    "                                }\n",
    "                            \n",
    "                            model_stats[model_name]['total_time'] += result['time']\n",
    "                            model_stats[model_name]['total_compression'] += result['compression_ratio']\n",
    "                            model_stats[model_name]['count'] += 1\n",
    "                        else:\n",
    "                            if model_name not in model_stats:\n",
    "                                model_stats[model_name] = {'errors': 0, 'count': 0}\n",
    "                            model_stats[model_name]['errors'] += 1\n",
    "        \n",
    "        # Display model performance summary\n",
    "        for model_name, stats in model_stats.items():\n",
    "            if 'count' in stats and stats['count'] > 0:\n",
    "                avg_time = stats['total_time'] / stats['count']\n",
    "                avg_compression = stats['total_compression'] / stats['count']\n",
    "                print(f\"\\n{model_name}:\")\n",
    "                print(f\"   Average Time: {avg_time:.3f}s\")\n",
    "                print(f\"   Average Compression: {avg_compression:.2f}\")\n",
    "                print(f\"   Success Rate: {stats['count']}/{stats['count'] + stats.get('errors', 0)}\")\n",
    "            else:\n",
    "                print(f\"\\n{model_name}: No successful runs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPhase 4: Main Execution Pipeline\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    data_paths = [\n",
    "        '/content/drive/MyDrive/finM/textData2/gd_sample_sy2017.csv',\n",
    "        '/content/drive/MyDrive/finM/textData2/gd_sample_sy2018.csv',\n",
    "        '/content/drive/MyDrive/finM/textData2/gd_sample_sy2019.csv',\n",
    "        '/content/drive/MyDrive/finM/textData2/gd_sample_sy2020.csv'\n",
    "    ]\n",
    "    \n",
    "    df = None\n",
    "    for path in data_paths:\n",
    "        try:\n",
    "            print(f\"🔍 Trying to load data from: {path}\")\n",
    "            df = load_and_explore_data(path)\n",
    "            if df is not None:\n",
    "                print(f\"Successfully loaded data from: {path}\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"Could not load data from any expected location\")\n",
    "        print(\" Please ensure your data file is in the correct path\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nInitializing HCF Analyzer...\")\n",
    "    hcf_analyzer = EnhancedHCFAnalyzer()\n",
    "    \n",
    "    company_analyzer = CompanyAnalyzer(hcf_analyzer)\n",
    "    \n",
    "    print(\"\\nStarting company analysis...\")\n",
    "    company_analyses = company_analyzer.analyze_all_companies(df)\n",
    "    \n",
    "    print(\"\\nGenerating company reports...\")\n",
    "    top_companies = sorted(\n",
    "        company_analyses.keys(),\n",
    "        key=lambda x: np.mean([a['strength_score'] for a in company_analyses[x].values()]),\n",
    "        reverse=True\n",
    "    )[:3]\n",
    "    \n",
    "    for company in top_companies:\n",
    "        report = company_analyzer.generate_company_report(company, company_analyses[company])\n",
    "        print(report)\n",
    "    \n",
    "    company_analyzer.generate_model_comparison_summary(company_analyses)\n",
    "    \n",
    "    print(\"\\nANALYSIS SUMMARY:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Total Companies Analyzed: {len(company_analyses)}\")\n",
    "    print(f\"Total Reviews Processed: {len(df)}\")\n",
    "    \n",
    "    print(\"\\nDIMENSION PERFORMANCE SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    for dimension in hcf_analyzer.hcf_dimensions.keys():\n",
    "        dimension_scores = []\n",
    "        for company_analysis in company_analyses.values():\n",
    "            if dimension in company_analysis:\n",
    "                dimension_scores.append(company_analysis[dimension]['strength_score'])\n",
    "        \n",
    "        if dimension_scores:\n",
    "            avg_score = np.mean(dimension_scores)\n",
    "            print(f\"{dimension}: {avg_score:.3f}\")\n",
    "    \n",
    "    print(\"\\nKey Improvements with Model Comparison:\")\n",
    "    print(\"• Added DistilBART for faster inference (50% smaller, ~60% faster)\")\n",
    "    print(\"• Implemented comprehensive model comparison system\")\n",
    "    print(\"• Performance metrics: time, compression ratio, success rate\")\n",
    "    print(\"• Side-by-side summary quality comparison\")\n",
    "    print(\"• Error handling and model availability checking\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
